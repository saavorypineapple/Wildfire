import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_curve, auc

st.set_page_config(page_title="ì‚°ë¶ˆ ì˜ˆì¸¡ AI ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ì„±ì‹œìš°ì™€ ì¹œêµ¬ë“¤ ì‚°ë¶ˆì˜ˆì¸¡ AI (ëª¨ë¸ë³„ ì„±ëŠ¥/ì‹œê°í™”)")

uploaded_file = st.file_uploader("fire.csv.xlsx íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["xlsx"])

if uploaded_file:
    df = pd.read_excel(uploaded_file)
    st.write("ë°ì´í„° ìƒ˜í”Œ:", df.head())

    # ë³€ìˆ˜ëª… ë§ì¶¤
    numeric_cols = ['top_tprt', 'avg_hmd', 'ave_wdsp', 'de_rnfl_qy']
    target_col = 'frfire_ocrn_nt'

    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° íƒ€ê²Ÿ ì´ì§„í™”
    df = df.dropna(subset=[target_col])
    for col in numeric_cols:
        df[col] = df[col].fillna(df[col].mean())
    df[target_col] = (df[target_col] > 0).astype(int)

    # ë°ì´í„° í–‰ìˆ˜, íƒ€ê²Ÿê°’ ì¢…ë¥˜ ì²´í¬
    st.write(f"ë¶„ì„ì— ì‚¬ìš©í•  ë°ì´í„° í–‰ ìˆ˜: {df.shape[0]}")
    X = df[numeric_cols]
    y = df[target_col]
    n_class = y.nunique()
    st.write(f"íƒ€ê²Ÿ(ì‚°ë¶ˆë°œìƒì—¬ë¶€) ê³ ìœ ê°’: {y.unique()} (í´ë˜ìŠ¤ ê°œìˆ˜: {n_class})")

    if df.shape[0] == 0 or n_class < 2:
        st.error(
            f"ëª¨ë¸ í•™ìŠµ/í‰ê°€ ë¶ˆê°€!\n"
            f"â†’ ë°ì´í„°ê°€ ì—†ê±°ë‚˜, íƒ€ê²Ÿ ë³€ìˆ˜({target_col})ì— 0/1ì´ ëª¨ë‘ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n"
            f"ì‚°ë¶ˆ ë°œìƒ(1) ë°ì´í„°ê°€ ë°˜ë“œì‹œ í¬í•¨ëœ íŒŒì¼ì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”."
        )
        st.stop()

    # ëª¨ë¸ í•™ìŠµ
    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    rf.fit(X, y)
    lr = LogisticRegression(max_iter=1000)
    lr.fit(X, y)
    xgb_model = xgb.XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss')
    xgb_model.fit(X, y)

    # ì˜ˆì¸¡ ë° ì˜ˆì¸¡í™•ë¥ 
    y_pred_rf = rf.predict(X)
    y_pred_lr = lr.predict(X)
    y_pred_xgb = xgb_model.predict(X)
    y_proba_rf = rf.predict_proba(X)[:, 1]
    y_proba_lr = lr.predict_proba(X)[:, 1]
    y_proba_xgb = xgb_model.predict_proba(X)[:, 1]

    # íƒ­ë³„ë¡œ ëª¨ë¸ ì‹œê°í™”
    tab1, tab2, tab3 = st.tabs(["ğŸŒ³ RandomForest", "ğŸ“ˆ Logistic Regression", "ğŸš€ XGBoost"])

    def show_model_results(y_true, y_pred, y_prob, model_name, feature_names, feature_importances=None):
        # í˜¼ë™í–‰ë ¬
        st.subheader(f"{model_name} - í˜¼ë™í–‰ë ¬")
        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])
        fig_cm, ax_cm = plt.subplots()
        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["No Fire", "Fire"])
        disp.plot(ax=ax_cm)
        st.pyplot(fig_cm)
        st.text(classification_report(y_true, y_pred))

        # ROC Curve
        st.subheader(f"{model_name} - ROC Curve")
        fpr, tpr, _ = roc_curve(y_true, y_prob)
        roc_auc = auc(fpr, tpr)
        fig_roc, ax_roc = plt.subplots()
        ax_roc.plot(fpr, tpr, label=f"AUC={roc_auc:.2f}")
        ax_roc.plot([0, 1], [0, 1], 'k--', label='Random')
        ax_roc.set_xlabel('False Positive Rate')
        ax_roc.set_ylabel('True Positive Rate')
        ax_roc.set_title(f"{model_name} ROC Curve")
        ax_roc.legend()
        ax_roc.grid(True)
        st.pyplot(fig_roc)

        # ë³€ìˆ˜ ì¤‘ìš”ë„
        if feature_importances is not None:
            st.subheader(f"{model_name} - ë³€ìˆ˜ ì¤‘ìš”ë„")
            imp_sorted_idx = np.argsort(feature_importances)[::-1]
            fig_imp, ax_imp = plt.subplots()
            ax_imp.bar(range(len(feature_importances)), feature_importances[imp_sorted_idx], align='center')
            ax_imp.set_xticks(range(len(feature_importances)))
            ax_imp.set_xticklabels(np.array(feature_names)[imp_sorted_idx], rotation=45)
            ax_imp.set_title("Feature Importances")
            st.pyplot(fig_imp)

    with tab1:
        st.header("RandomForest ê²°ê³¼")
        show_model_results(
            y, y_pred_rf, y_proba_rf, "RandomForest", numeric_cols, rf.feature_importances_
        )

    with tab2:
        st.header("Logistic Regression ê²°ê³¼")
        show_model_results(
            y, y_pred_lr, y_proba_lr, "Logistic Regression", numeric_cols
        )

    with tab3:
        st.header("XGBoost ê²°ê³¼")
        show_model_results(
            y, y_pred_xgb, y_proba_xgb, "XGBoost", numeric_cols, xgb_model.feature_importances_
        )

else:
    st.info("ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
